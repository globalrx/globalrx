{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e13460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "data_file_ema = 'output/human-rx-drug-ema.json'\n",
    "data_file_fda = 'output/human-rx-drug-openfda.json'\n",
    "RUN_DIAGNOSTIC = False\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30574d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load data (takes a fair amount of memory)\n",
    "\n",
    "with open(data_file_ema) as f:\n",
    "    data_ema = json.load(f)\n",
    "\n",
    "with open(data_file_fda) as f:\n",
    "    data_fda = json.load(f)\n",
    "    \n",
    "keys_ema, drugs_ema = zip(*data_ema.items())\n",
    "sections_ema = [d['Label Text'].keys() for d in drugs_ema]\n",
    "sections_ema = sorted(set([s for slist in sections_ema for s in slist]))\n",
    "\n",
    "keys_fda, drugs_fda = zip(*data_fda.items())\n",
    "sections_fda = [d['Label Text'].keys() for d in drugs_fda]\n",
    "sections_fda = sorted(set([s for slist in sections_fda for s in slist]))\n",
    "\n",
    "\n",
    "\n",
    "#%% how many words are in each fda section?\n",
    "if RUN_DIAGNOSTIC:\n",
    "    slens = {s.replace(' ','_').lower():[] for s in sections_fda}\n",
    "    for d in tqdm(drugs_fda):\n",
    "        for s,val in d['Label Text'].items():\n",
    "            for v in val:\n",
    "                slens[s].append(len(v.split()))\n",
    "    for s,lens in slens.items():\n",
    "        print(np.mean(lens), s)\n",
    "\n",
    "\n",
    "#%% find pairs of ema/fda drugs with matching brand or generic names\n",
    "\n",
    "bnames_ema = [d['metadata']['Medicine name'] for d in drugs_ema]\n",
    "gnames_ema = [d['metadata']['International non-proprietary name (INN) / common name'] for d in drugs_ema]\n",
    "snames_ema = [d['metadata']['Active substance'] for d in drugs_ema]\n",
    "\n",
    "bnames_fda = ['' if 'brand_name' not in d['metadata'].keys() else d['metadata']['brand_name'][0] for d in drugs_fda]\n",
    "gnames_fda = ['' if 'generic_name' not in d['metadata'].keys() else d['metadata']['generic_name'][0] for d in drugs_fda]\n",
    "snames_fda = ['' if 'substance_name' not in d['metadata'].keys() else d['metadata']['substance_name'][0] for d in drugs_fda]\n",
    "find_in_list = lambda x,xlist: list(np.where([x==z for z in xlist])[0])\n",
    "\n",
    "def match_ema_to_fda(drug_e):\n",
    "    bname_ema = drug_e['metadata']['Medicine name']\n",
    "    gname_ema = drug_e['metadata']['International non-proprietary name (INN) / common name']\n",
    "    sname_ema = drug_e['metadata']['Active substance']\n",
    "    \n",
    "    matches_b = find_in_list(bname_ema.lower(), [n.lower() for n in bnames_fda])\n",
    "    matches_g = find_in_list(gname_ema.lower(), [n.lower() for n in gnames_fda])\n",
    "    matches_s = find_in_list(sname_ema.lower(), [n.lower() for n in snames_fda])\n",
    "    \n",
    "    matches = list(set(matches_b + matches_g + matches_s))\n",
    "    return [drugs_fda[m] for m in matches]\n",
    "    \n",
    "\n",
    "#%% find matching fda for each ema (capped), save embeddings to disk (long computation)\n",
    "# warning: do not run this cell unless you need to re-compute embeddings\n",
    "\n",
    "# max sequence length = 512\n",
    "model = SentenceTransformer('allenai/scibert_scivocab_uncased')\n",
    "\n",
    "# This is the core code for comparing semantic similarity between sections:\n",
    "#   The model will ignore anything beyond 512 tokens (~300-400 words),\n",
    "#   so I slice section text into segments of <= 256 words, compute \n",
    "#   SciBERT embedding vectors for each one (dim=768), and return the average.\n",
    "#   For a given label (or list of labels), I do that section by section\n",
    "#   and stack the results into a matrix. For analysis purposes I'd be\n",
    "#   averaging the resulting matrices across a list of labels that\n",
    "#   represent the same drug (e.g. with identical generic name)\n",
    "\n",
    "def compute_section_embedding(text, word_count=256):\n",
    "    n_segments = 1 + len(text.split()) // word_count\n",
    "    vecs = np.zeros((n_segments,768))\n",
    "    for i in range(n_segments):\n",
    "        segment = text.split()[ (i)*word_count : (i+1)*word_count ]\n",
    "        vecs[i,:] = model.encode( ' '.join(segment) )\n",
    "    return np.mean(vecs, axis=0)\n",
    "\n",
    "def compute_drug_embedding(sections, drugs):\n",
    "    vecs = np.zeros((len(sections),768, len(drugs)))\n",
    "    for d,drug in enumerate(drugs):\n",
    "        for s,section in enumerate(sections):\n",
    "            if section in drug['Label Text'].keys():\n",
    "                texts = drug['Label Text'][section]\n",
    "                texts = list(set(texts))\n",
    "                v = [compute_section_embedding(t) for t in texts]\n",
    "                vecs[s,:,d] = np.array(v).mean(axis=0)\n",
    "    return vecs\n",
    "    \n",
    "\n",
    "all_vecs_e = []\n",
    "all_vecs_f = []\n",
    "max_matches = 20\n",
    "# note: most ema drugs match 0-10 fda products, long tail from ~30 to ~150\n",
    "\n",
    "for drug_e in tqdm(drugs_ema):\n",
    "    drugs_f = match_ema_to_fda(drug_e)\n",
    "    drugs_f = drugs_f[:max_matches]\n",
    "    \n",
    "    vecs_e = compute_drug_embedding(sections_ema, [drug_e])\n",
    "    vecs_f = compute_drug_embedding(sections_fda, drugs_f)\n",
    "\n",
    "    all_vecs_e.append(vecs_e)\n",
    "    all_vecs_f.append(vecs_f)\n",
    "\n",
    "# note: can't use np.savez because fda arrays are mismatched sizes, awkward\n",
    "with open('output/scibert-embeddings-ema.pkl', 'wb') as f:\n",
    "    pickle.dump(all_vecs_e, f)\n",
    "with open('output/scibert-embeddings-openfda.pkl', 'wb') as f:\n",
    "    pickle.dump(all_vecs_f, f)\n",
    "\n",
    "# simplified output format:\n",
    "#  csv with ema generic name, average of embedding vectors (all)\n",
    "#  csv with fda generic name, average of embedding vectors (those with a match)\n",
    "\n",
    "    \n",
    "#%% reload embeddings from disk\n",
    "\n",
    "with open('output/scibert-embeddings-ema.pkl', 'rb') as f:\n",
    "    all_vecs_e = pickle.load(f)\n",
    "with open('output/scibert-embeddings-openfda.pkl', 'rb') as f:\n",
    "    all_vecs_f = pickle.load(f)\n",
    "\n",
    "\n",
    "# omit empty ema sections, these 3 headers have all their text in sub-sections\n",
    "dummies = ['Clinical Particulars',\n",
    "           'Pharmacological Properties',\n",
    "           'Pharmaceutical Particulars']\n",
    "keep_rows = [s not in dummies for s in sections_ema]\n",
    "all_vecs_e = [v[keep_rows,:] for v in all_vecs_e]\n",
    "\n",
    "# reformat fda section names for readability (and match EMA)\n",
    "sections_fda = [s.replace('_',' ').title().replace('Spl','SPL') for s in sections_fda]\n",
    "\n",
    "#%% aggregate similarity matrix via matching drugs pairwise\n",
    "\n",
    "cosims = []\n",
    "for i,ve in enumerate(all_vecs_e):\n",
    "    vf = all_vecs_f[i]\n",
    "    if vf.shape[-1]>0:\n",
    "        ve = ve.mean(axis=-1)\n",
    "        vf = vf.mean(axis=-1)\n",
    "        cosim = np.array(cos_sim(ve,vf))\n",
    "        cosims.append(cosim)\n",
    "\n",
    "cosims = np.ma.masked_values(cosims, 0)\n",
    "csarr = np.ma.mean(cosims**4, axis=0)\n",
    "\n",
    "keep_cols = ~csarr.mask.any(axis=0)\n",
    "csarr = csarr[:,keep_cols]\n",
    "labels_col = [sections_fda[i] for i in np.where(keep_cols)[0]]\n",
    "labels_row = [sections_ema[i] for i in np.where(keep_rows)[0]]\n",
    "\n",
    "plt.figure(figsize=(16,12), dpi=150)\n",
    "im = plt.imshow(csarr)\n",
    "plt.gca().set_aspect(1)\n",
    "daspect = csarr.shape[0]/csarr.shape[1]\n",
    "plt.colorbar(im, fraction=0.046*daspect, pad=0.04)\n",
    "plt.title('SciBERT Embedding Cosine Similarity \\nEMA-FDA Matched Pairs', fontsize=16)\n",
    "plt.xlabel('FDA Label Section')\n",
    "plt.ylabel('EMA Label Section')\n",
    "plt.xticks(range(csarr.shape[1]), labels_col, rotation=90, size='small')\n",
    "plt.yticks(range(csarr.shape[0]), labels_row, size='small')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#%% aggregate similarity matrix via matching drugs all-to-all\n",
    "\n",
    "cosims, ct = np.zeros((26,81)), 0\n",
    "for ve in tqdm(all_vecs_e):\n",
    "    ve = ve.mean(axis=-1)\n",
    "    for vf in all_vecs_f:\n",
    "        if vf.shape[-1]>0:\n",
    "            vf = vf.mean(axis=-1)\n",
    "            cosims += np.array(cos_sim(ve,vf))**4\n",
    "            ct += 1\n",
    "\n",
    "# full array won't fit in memory if we do it the same way\n",
    "csarr = np.ma.masked_values(cosims/ct, 0)\n",
    "\n",
    "#keep_cols = ~csarr.mask.any(axis=0)\n",
    "csarr = csarr[:,keep_cols]\n",
    "labels_col = [sections_fda[i] for i in np.where(keep_cols)[0]]\n",
    "labels_row = [sections_ema[i] for i in np.where(keep_rows)[0]]\n",
    "\n",
    "plt.figure(figsize=(16,12), dpi=150)\n",
    "im = plt.imshow(csarr)\n",
    "plt.gca().set_aspect(1)\n",
    "daspect = csarr.shape[0]/csarr.shape[1]\n",
    "plt.colorbar(im, fraction=0.046*daspect, pad=0.04)\n",
    "plt.title('SciBERT Embedding Cosine Similarity \\nEMA-FDA Overall', fontsize=16)\n",
    "plt.xlabel('FDA Label Section')\n",
    "plt.ylabel('EMA Label Section')\n",
    "plt.xticks(range(csarr.shape[1]), labels_col, rotation=90, size='small')\n",
    "plt.yticks(range(csarr.shape[0]), labels_row, size='small')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#%% section similarity within agency: EMA\n",
    "\n",
    "cosims = []\n",
    "for i,v in enumerate(all_vecs_e):\n",
    "    v = v.mean(axis=-1)\n",
    "    cosim = np.array(cos_sim(v,v))\n",
    "    cosims.append(cosim)\n",
    "\n",
    "cosims = np.ma.masked_values(cosims, 0)\n",
    "csarr = np.ma.mean(cosims**4, axis=0)\n",
    "\n",
    "labels_row = [sections_ema[i] for i in np.where(keep_rows)[0]]\n",
    "\n",
    "plt.figure(figsize=(12,12), dpi=150)\n",
    "im = plt.imshow(csarr)\n",
    "plt.gca().set_aspect(1)\n",
    "daspect = csarr.shape[0]/csarr.shape[1]\n",
    "plt.colorbar(im, fraction=0.046*daspect, pad=0.04)\n",
    "plt.title('SciBERT Embedding Cosine Similarity \\nEMA Only', fontsize=16)\n",
    "plt.xlabel('EMA Label Section')\n",
    "plt.ylabel('EMA Label Section')\n",
    "plt.xticks(range(csarr.shape[1]), labels_row, rotation=90, size='small')\n",
    "plt.yticks(range(csarr.shape[0]), labels_row, size='small')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#%% section similarity within agency: FDA\n",
    "\n",
    "cosims = []\n",
    "for i,v in enumerate(all_vecs_f):\n",
    "    if v.shape[-1]>0:\n",
    "        v = v.mean(axis=-1)\n",
    "        cosim = np.array(cos_sim(v,v))\n",
    "        cosims.append(cosim)\n",
    "\n",
    "cosims = np.ma.masked_values(cosims, 0)\n",
    "csarr = np.ma.mean(cosims**4, axis=0)\n",
    "\n",
    "#keep_cols = np.where(~csarr.mask.any(axis=0))[0] # keep same cols as before\n",
    "csarr = csarr[:,keep_cols][keep_cols,:]\n",
    "labels_col = [sections_fda[i].replace('_',' ').title().replace('Spl','SPL') for i in keep_cols]\n",
    "\n",
    "plt.figure(figsize=(12,12), dpi=150)\n",
    "im = plt.imshow(csarr)\n",
    "plt.gca().set_aspect(1)\n",
    "daspect = csarr.shape[0]/csarr.shape[1]\n",
    "plt.colorbar(im, fraction=0.046*daspect, pad=0.04)\n",
    "plt.title('SciBERT Embedding Cosine Similarity \\nFDA Only', fontsize=16)\n",
    "plt.xlabel('FDA Label Section')\n",
    "plt.ylabel('FDA Label Section')\n",
    "plt.xticks(range(csarr.shape[1]), labels_col, rotation=90, size='small')\n",
    "plt.yticks(range(csarr.shape[0]), labels_col, size='small')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#%% next goal: collapse all identical generic names? probably not needed\n",
    "if RUN_DIAGNOSTIC:\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    enames = pd.DataFrame({'generic':gnames_ema, 'brand':bnames_ema})\n",
    "    enames = enames.applymap(lambda x: x.lower())\n",
    "    enames['matches'] = [match_ema_to_fda(d) for d in data_ema.values()] # drugs\n",
    "    enames['matches'] = enames['matches'].apply(lambda x: [d['metadata']['generic_name'] for d in x])\n",
    "    enames['matches'] = enames['matches'].apply(lambda x: sum(x,[])) # flatten\n",
    "    enames['n_matches'] = enames['matches'].apply(lambda x: len(x))\n",
    "    enames['c_matches'] = enames['matches'].apply(lambda x: len(set(x)))\n",
    "    \n",
    "    fnames = pd.DataFrame({'generic':gnames_fda, 'brand':bnames_fda})\n",
    "    fnames = fnames.applymap(lambda x: x.lower())\n",
    "\n",
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
